2025-07-23 10:45:53,920 | INFO     | 0080 | start greek data processing -- 2025-07-23 10:45:53.920837
2025-07-23 10:45:55,370 | INFO     | 0194 | Training model
2025-07-23 10:45:55,370 | INFO     | 0196 | Train greek_rnn_no_dropout model specs: embed_size: 300, hidden_size: 300, proj_size: 150, rnn n layers: 4, share: False, dropout: 0.0
2025-07-23 10:45:55,599 | INFO     | 0216 | RNN(
  (embed): Embedding(35, 300)
  (scale_up): Linear(in_features=300, out_features=300, bias=True)
  (rnn): LSTM(300, 150, num_layers=4, batch_first=True, bidirectional=True)
  (out): Linear(in_features=300, out_features=300, bias=True)
  (dropout): Dropout(p=0.0, inplace=False)
)
2025-07-23 10:45:55,599 | INFO     | 0162 | total parameter count = 2,350,500
2025-07-23 10:46:46,650 | INFO     | 0238 | Now training LSTM
2025-07-23 10:46:46,651 | INFO     | 0205 | Mask type: smart - dynamic
2025-07-23 10:46:46,651 | INFO     | 0206 | Training data read in with 75500 lines
2025-07-23 11:46:24,588 | INFO     | 0223 | train=75,500 23,007,539 27,416,340 1.2 dev=9,437 2,895,734 3,549,133 1.2 bs=1 lr=0.0003 [300, 300, 150, 4, False, 0.0, 0.15, 35]
2025-07-23 11:46:24,590 | INFO     | 0231 | 0 tr loss   0.0921   0.0773 -- dev loss   0.3280   0.2676 -- incremental_batch_size:    1 time elapsed: 3575.6
2025-07-23 11:46:24,590 | INFO     | 0247 | dev masked total: 307871, correct predictions: 41586, simple accuracy: 0.135
2025-07-23 12:46:38,822 | INFO     | 0231 | 1 tr loss   0.0858   0.0720 -- dev loss   0.3139   0.2561 -- incremental_batch_size:    1 time elapsed: 7189.8
2025-07-23 12:46:38,824 | INFO     | 0247 | dev masked total: 307871, correct predictions: 57176, simple accuracy: 0.186
2025-07-23 13:46:59,492 | INFO     | 0231 | 2 tr loss   0.0834   0.0700 -- dev loss   0.3148   0.2568 -- incremental_batch_size:    2 time elapsed: 10810.5
2025-07-23 13:46:59,494 | INFO     | 0241 | early exit
2025-07-23 13:51:19,229 | INFO     | 0332 | masked total: 307871, correct predictions: 56519, simple accuracy: 0.184, mismatch: 0
